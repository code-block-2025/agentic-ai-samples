{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5264b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76323f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace1303e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "    <h2>Prompt Chaining Example</h2>\n",
       "    <b>Step 1:-</b> Ask LLM to propose hard questions to judge IQ. </br>\n",
       "    <b>Step 2:-</b> Ask LLM to provide answer to generated question in subsequent prompt.   \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If two trains start from the same station traveling in opposite directions, one at 60 mph and the other at 90 mph, and after how many hours will the distance between them be 450 miles?\n"
     ]
    }
   ],
   "source": [
    "if openai_api_key == False:\n",
    "    display(Markdown(\"\"\"\n",
    "        <h2>Warning: Cannot run prompt chaining example as OPEN API Key not set in .env file. Please set the key to proceed.</h2>\n",
    "    \"\"\"))\n",
    "else:\n",
    "    display(Markdown(\"\"\"\n",
    "    <h2>Prompt Chaining Example</h2>\n",
    "    <b>Step 1:-</b> Ask LLM to propose hard questions to judge IQ. </br>\n",
    "    <b>Step 2:-</b> Ask LLM to provide answer to generated question in subsequent prompt.   \n",
    "    \"\"\"))\n",
    "\n",
    "    # And now we'll create an instance of the OpenAI class\n",
    "    openai = OpenAI()\n",
    "\n",
    "    # And now - let's ask for a question:\n",
    "    question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "    messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "    # ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    question = response.choices[0].message.content\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ced1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "If two trains are traveling in opposite directions, their speeds add up when calculating the distance between them.\n",
       "\n",
       "- Speed of first train = 60 mph\n",
       "- Speed of second train = 90 mph\n",
       "- Combined speed = 60 + 90 = 150 mph\n",
       "- Distance between them = 450 miles\n",
       "\n",
       "Time \\( t = \\frac{\\text{Distance}}{\\text{Speed}} = \\frac{450}{150} = 3 \\) hours\n",
       "\n",
       "**Answer:** They will be 450 miles apart after **3 hours**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# form a new messages list with response to question.\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
